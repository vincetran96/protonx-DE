{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create spark context and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/28 15:08:11 WARN Utils: Your hostname, vinces-MBP.local resolves to a loopback address: 127.0.0.1; using 192.168.1.5 instead (on interface en0)\n",
      "23/09/28 15:08:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/28 15:08:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"local[*]\")\n",
    "    .setAppName(\"Day_5_Quizz\")\n",
    ")\n",
    "\n",
    "sc = (\n",
    "    SparkContext(conf=conf)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(conf=sc.getConf())\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filepaths = [\n",
    "    str(p) for p in \n",
    "    Path(\"./day_5_data\").rglob(\"amazon_us_reviews-train-00004-of-00005.parquet\") \n",
    "]\n",
    "df = spark.read.parquet(*filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: long (nullable = true)\n",
      " |-- verified_purchase: long (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|product_category|helpful_votes|\n",
      "+----------------+-------------+\n",
      "|         Apparel|           17|\n",
      "|         Apparel|            0|\n",
      "+----------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['product_category', 'helpful_votes']).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df.select('product_id', 'review_body').rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top words associated with each product\n",
    "- The words must not be in the top words across all products (e.g., words like \"the\")\n",
    "- Need to find top 1k words from all products first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Top 1k words from all products\n",
    "def gen_words(row):\n",
    "    '''Generate words from a review body str'''\n",
    "    for word in row['review_body'].split(\" \"):\n",
    "        yield (word, 1)\n",
    "\n",
    "rdd_top1kWords = (\n",
    "    rdd\n",
    "    .flatMap(gen_words)\n",
    "    .reduceByKey(lambda x,y: x+y)\n",
    "    .sortBy(lambda row: row[1], ascending=False)\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda row: row[1] < 1000) # This way we can get top 1k words in RDD form\n",
    "    .map(lambda row: row[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 985246), ('I', 865286)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_top1kWords.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All words from each product ID\n",
    "def gen_word_product(row):\n",
    "    '''Generate tuples of word, product ID\n",
    "    from a row\n",
    "    '''\n",
    "    for word in row['review_body'].split(\" \"):\n",
    "        yield (word, (row['product_id'], 1))\n",
    "\n",
    "# Output = [ ('the','PID0',1), ... ]\n",
    "rdd_word_product = (\n",
    "    rdd\n",
    "    .flatMap(gen_word_product)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "# Exclude words from the top 1k\n",
    "# Transform a row to (('PIB0', 'the'), 1)\n",
    "# Transform a row to ('PIB0', 'the', 1)\n",
    "rdd_product_word_non1k = (\n",
    "    rdd_word_product\n",
    "    .leftOuterJoin(rdd_top1kWords)\n",
    "    .filter(lambda row: row[1][1] == None)\n",
    "    .map(lambda row: ((row[1][0][0], row[0]), row[1][0][1]))\n",
    "    .reduceByKey(lambda x,y: x+y)\n",
    "    .map(lambda row: (row[0][0], row[0][1], row[1]))\n",
    ")\n",
    "\n",
    "topNWords_product = (\n",
    "    rdd_product_word_non1k\n",
    "    .groupBy(lambda row: row[0])\n",
    "    .flatMap(lambda row: nlargest(5, row[1], key=lambda tup: tup[2]))\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topNWords_prod_df = pd.DataFrame(topNWords_product, columns=['PID','word','count'])\n",
    "topNWords_prod_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18772</th>\n",
       "      <td>B0007CKRTA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142326</th>\n",
       "      <td>B001CGGXQ6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115863</th>\n",
       "      <td>B0012OAMFG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142329</th>\n",
       "      <td>B001CGH1VM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5574</th>\n",
       "      <td>B00012UPAW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61002</th>\n",
       "      <td>B000JRBBF2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61003</th>\n",
       "      <td>B000JRBG6G</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61004</th>\n",
       "      <td>B000JRBJ8Q</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60983</th>\n",
       "      <td>B000JR3NY4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166701</th>\n",
       "      <td>B001LRMV9O</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166702 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PID  size\n",
       "18772   B0007CKRTA     1\n",
       "142326  B001CGGXQ6     1\n",
       "115863  B0012OAMFG     1\n",
       "142329  B001CGH1VM     1\n",
       "5574    B00012UPAW     1\n",
       "...            ...   ...\n",
       "61002   B000JRBBF2     5\n",
       "61003   B000JRBG6G     5\n",
       "61004   B000JRBJ8Q     5\n",
       "60983   B000JR3NY4     5\n",
       "166701  B001LRMV9O     5\n",
       "\n",
       "[166702 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    topNWords_prod_df\n",
    "    .groupby('PID', as_index=False)\n",
    "    .size()\n",
    "    .sort_values('size', ascending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255430</th>\n",
       "      <td>B000JR3NY4</td>\n",
       "      <td>upgrade</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255431</th>\n",
       "      <td>B000JR3NY4</td>\n",
       "      <td>Dec.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255432</th>\n",
       "      <td>B000JR3NY4</td>\n",
       "      <td>reason.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255433</th>\n",
       "      <td>B000JR3NY4</td>\n",
       "      <td>shipping.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255434</th>\n",
       "      <td>B000JR3NY4</td>\n",
       "      <td>later</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PID       word  count\n",
       "255430  B000JR3NY4    upgrade      1\n",
       "255431  B000JR3NY4       Dec.      1\n",
       "255432  B000JR3NY4    reason.      1\n",
       "255433  B000JR3NY4  shipping.      1\n",
       "255434  B000JR3NY4      later      1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topNWords_prod_df[topNWords_prod_df['PID'] == 'B000JR3NY4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding top words associated with each product seems to produce a very \"sparse\" result (i.e., no insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top words associated with each product category\n",
    "- The words must not be in the top words across all products (e.g., words like \"the\")\n",
    "- Need to find top 1k words from all products first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All words from each product cat\n",
    "def gen_word_cat(row):\n",
    "    '''Generate tuples of word, product cat\n",
    "    from a row\n",
    "    '''\n",
    "    for word in row['review_body'].split(\" \"):\n",
    "        yield (word, (row['product_category'], 1))\n",
    "\n",
    "rdd = df.select('product_category', 'review_body').rdd\n",
    "\n",
    "# Output = [ ('the','cat0',1), ... ]\n",
    "rdd_word_cat = (\n",
    "    rdd\n",
    "    .flatMap(gen_word_cat)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "# Exclude words from the top 1k\n",
    "# Transform a row to (('cat0', 'the'), 1)\n",
    "# Transform a row to ('cat0', 'the', 1)\n",
    "rdd_cat_word_non1k = (\n",
    "    rdd_word_cat\n",
    "    .leftOuterJoin(rdd_top1kWords)\n",
    "    .filter(lambda row: row[1][1] == None)\n",
    "    .map(lambda row: ((row[1][0][0], row[0]), row[1][0][1]))\n",
    "    .reduceByKey(lambda x,y: x+y)\n",
    "    .map(lambda row: (row[0][0], row[0][1], row[1]))\n",
    ")\n",
    "\n",
    "topNWords_cat = (\n",
    "    rdd_cat_word_non1k\n",
    "    .groupBy(lambda row: row[0])\n",
    "    .flatMap(lambda row: nlargest(5, row[1], key=lambda tup: tup[2]))\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_cat</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apparel</td>\n",
       "      <td>amazing</td>\n",
       "      <td>2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apparel</td>\n",
       "      <td>standard</td>\n",
       "      <td>2516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_cat      word  count\n",
       "0     Apparel   amazing   2517\n",
       "1     Apparel  standard   2516"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topNWords_cat_df = pd.DataFrame(topNWords_cat, columns=['product_cat','word','count'])\n",
    "topNWords_cat_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_cat</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apparel</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_cat  size\n",
       "0     Apparel     5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    topNWords_cat_df\n",
    "    .groupby('product_cat', as_index=False)\n",
    "    .size()\n",
    "    .sort_values('size', ascending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irrelevant reviews\n",
    "- For each product ID, create a list of random irrelevant reviews\n",
    "- Irrelevant = not in the list of all reviews of that product\n",
    "\n",
    "Not sure if we can use both RDD and DF for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a list of ALL review IDs for reference\n",
    "ref_reviews = df.select(['review_id']).collect()\n",
    "ref_reviews = [ row['review_id'] for row in ref_reviews ]\n",
    "ref_reviews_brdcst = sc.broadcast(ref_reviews)\n",
    "ref_reviews_brdcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the RDD method\n",
    "\n",
    "def list_combine_rdd(x):\n",
    "    return [x]\n",
    "\n",
    "def list_merge_rdd(x,y):\n",
    "    x.append(y)\n",
    "    return x\n",
    "\n",
    "def list_extend_rdd(x,y):\n",
    "    x.extend(y)\n",
    "    return x\n",
    "\n",
    "prod_review_rdd = df.select(['product_id','review_id']).rdd\n",
    "\n",
    "# Collect all reviews of each product\n",
    "prod_allReviews_rdd = (\n",
    "    prod_review_rdd\n",
    "    .map(lambda row: (row['product_id'], row['review_id']))\n",
    "    .combineByKey(list_combine_rdd, list_merge_rdd, list_extend_rdd)\n",
    ")\n",
    "\n",
    "def sample_irr_rv_rdd(row, seed=1):\n",
    "    '''Samples irrelevant reviews\n",
    "\n",
    "    A row must look like this: `('PID0', ['RV0','RV1'])`\n",
    "\n",
    "    Map this to a RDD\n",
    "    '''\n",
    "    sample_space = list(set(ref_reviews_brdcst.value).difference(set(row[1])))\n",
    "    random.seed(seed)\n",
    "    return (\n",
    "        row[0],\n",
    "        row[1],\n",
    "        random.sample(sample_space, min(len(sample_space),5))\n",
    "    )\n",
    "\n",
    "product_bothReviews_rdd = (\n",
    "    prod_allReviews_rdd\n",
    "    .map(sample_irr_rv_rdd)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('B001LRM76Q',\n",
       "  ['RWBRDXHX1B3Y8'],\n",
       "  ['R2YTD5HINM6J1D',\n",
       "   'R2XTXZ925N98XY',\n",
       "   'R3JBN1H7DDWVQ3',\n",
       "   'R2MFXZERMWGEL8',\n",
       "   'R38ETWSLKWLISM']),\n",
       " ('B001LRM6BW',\n",
       "  ['R2O3SBNPLMN9MI'],\n",
       "  ['R2YTD5HINM6J1D',\n",
       "   'R2XTXZ925N98XY',\n",
       "   'R3JBN1H7DDWVQ3',\n",
       "   'R11300M2GHKAR5',\n",
       "   'R38ETWSLKWLISM'])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_bothReviews_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- review_id_arr: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- irr_review_id_arr: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    product_bothReviews_rdd\n",
    "    .toDF(['product_id','review_id_arr','irr_review_id_arr'])\n",
    "    .printSchema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DF method\n",
    "\n",
    "product_allReviews_df = (\n",
    "    df\n",
    "    .groupby(['product_id'])\n",
    "    .agg(F.collect_list('review_id').alias('review_id_arr'))\n",
    ")\n",
    "\n",
    "def sample_irr_rv_df(array, seed=1):\n",
    "    '''Samples irrelevant reviews\n",
    "\n",
    "    Map this to a DF column\n",
    "    '''\n",
    "    sample_space = list(set(ref_reviews_brdcst.value).difference(set(array)))\n",
    "    random.seed(seed)\n",
    "    return random.sample(sample_space, min(len(sample_space),5))\n",
    "\n",
    "# Register UDF\n",
    "sample_irr_rv_udf = F.udf(sample_irr_rv_df, returnType=ArrayType(StringType()))\n",
    "\n",
    "product_bothReviews_df = (\n",
    "    product_allReviews_df\n",
    "    .withColumn('irr_review_id_arr', sample_irr_rv_udf(F.col('review_id_arr')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|product_id|       review_id_arr|   irr_review_id_arr|\n",
      "+----------+--------------------+--------------------+\n",
      "|0000032034|[R2THEEBLJRYPRH, ...|[R13LG32TBZYYBD, ...|\n",
      "|1465014578|[RIB8YVLWG5B5I, R...|[R12AB1XYK66Z93, ...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "product_bothReviews_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- review_id_arr: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- irr_review_id_arr: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_bothReviews_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloner39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
